<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLMs, AI, and the Sunk Cost Fallacy of Knowledge Acquisition in 2025 | Nessim Ben Abbes</title>
    <meta name="description" content="A continuation of thoughts on AI and software engineering, exploring how abstractions have always defined human progress and why cognitive prowess is the next skill to be abstracted." />
    <meta name="author" content="Nessim Ben Abbes" />
    <meta name="robots" content="index, follow" />
    <link rel="canonical" href="https://nessimbena.github.io/blogposts/sunk-cost-fallacy-knowledge-acquisition.html" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="LLMs, AI, and the Sunk Cost Fallacy of Knowledge Acquisition in 2025" />
    <meta property="og:description" content="A continuation of thoughts on AI and software engineering, exploring how abstractions have always defined human progress." />
    <meta property="og:url" content="https://nessimbena.github.io/blogposts/sunk-cost-fallacy-knowledge-acquisition.html" />
    <meta property="og:site_name" content="Nessim Ben Abbes" />
    <meta property="article:author" content="Nessim Ben Abbes" />
    <meta property="article:published_time" content="2025-12-21" />
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="LLMs, AI, and the Sunk Cost Fallacy of Knowledge Acquisition in 2025" />
    <meta name="twitter:description" content="A continuation of thoughts on AI and software engineering, exploring how abstractions have always defined human progress." />
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "headline": "LLMs, AI, and the Sunk Cost Fallacy of Knowledge Acquisition in 2025",
        "description": "A continuation of thoughts on AI and software engineering, exploring how abstractions have always defined human progress and why cognitive prowess is the next skill to be abstracted.",
        "author": {"@type": "Person", "name": "Nessim Ben Abbes"},
        "datePublished": "2025-12-21",
        "publisher": {"@type": "Person", "name": "Nessim Ben Abbes"}
    }
    </script>
    <link rel="stylesheet" href="../index.css" />
</head>
<body>
    <div class="book-container">
        <div id="header"></div>

        <article>
            <h1>LLMs, AI, and the Sunk Cost Fallacy of Knowledge Acquisition in 2025</h1>
            <p class="post-date">December 2025</p>

            <p>This will be a continuation, about one year later, of my previous blog post "LLMs, AI and Software Engineering." In a quick summary, in that blog post I argued that LLMs will eventually write most of the code, and engineers will still be the main people driving them, under a new, unspecified at that time, programming language.</p>

            <p>One year later, and I think we have started to see glimpses of this new paradigm. OpenAI with its Codex<sup><a href="#ref1">[1]</a></sup>, Anthropic with Claude Code, the open-source community with opencode, and the list goes on<sup><a href="#ref2">[2]</a></sup>. All these offer a new way of not only writing code but also thinking about it. With the advent of context engineering, few-shot prompting, and other techniques, we are witnessing in real time a new way to come up with algorithms<sup><a href="#ref3">[3]</a></sup><sup><a href="#ref4">[4]</a></sup>.</p>

            <p>These model harnesses are becoming more relevant, providing improvements in LLM benchmarks, to a point where factuality (or LLM hallucinations) has been proven to be greatly reduced by tool use<sup><a href="#ref5">[5]</a></sup>. This is coherent with the previous theory on the need for physicality for AI: the ability to interact with its environment, when coupled with in-context learning, makes for a powerful reasoning machine--something we have never witnessed outside of humans. The scientific method can finally be conducted by something other than us.</p>

            <hr />

            <p>All these breakthroughs and their effect on industry have shown that a great portion of us, technologists, are in fact not always on the side of technology.</p>

            <p>While many think that such technology will open up a new door for human scientific endeavour, others see this as a cheap, unreasonable way to reduce our ability to understand the world (or our software).</p>

            <p>Make no mistake, however: they are not wrong.</p>

            <p>LLMs (with their harnesses), if they manage to maintain this level of year on year improvement, will soon offer an abstraction layer for all symbolic manipulation.</p>

            <p>The consequences of such abstraction layer on the scientific world are honestly beyond anything I can imagine.</p>

            <p>Yet an abstraction, by definition, acts as a veil on the underlying mechanisms that explain how reality is being manipulated. Yet I argue that this is beneficial, and all of human progress comes down to inventing new abstractions.</p>

            <hr />

            <h2>The History of Human Abstraction</h2>

            <p>I have previously talked about the original resistance to early compilers, and mentioned Luddites, but failed to explain that we have repeatedly, across the history of humanity, abstracted foundational skills that used to define who we are.</p>

            <p>Agriculture abstracted away hunting and gathering, a skill so foundational that humans from that era were named after it.</p>

            <p>Gunpowder abstracted away physical combat prowess; swords and shields became toys in less than a century.</p>

            <p>The Industrial Revolution abstracted away human physical effort, another defining feature that civilisations were built upon.</p>

            <p>Yet, we are still looking for methods to make food security more economical and ethical. We are still looking for ways to improve on physical combat prowess through different tournaments. We are still looking for new physics to replace the energy that we built the Industrial Revolution on. Today's energy production has evolved beyond anything our ancestors imagined, and still receives constant innovation--as do agriculture and martial arts.</p>

            <p>Why?</p>

            <hr />

            <h2>Humans Are Visionaries</h2>

            <p>My argument is that we were wrong. We didn't change as we have progressed in the tech tree; we in fact were always the same: visionaries.</p>

            <p>In 2025, we are mainly defined by our cognitive prowess. IQ discussions as well as knowledge acquisition are the main drivers of socioeconomic evolution. This will not last for long. I believe that in less than five years, the run-of-the-mill LLM will be smarter than any human that has ever lived. We are not very far from this, and this feeling is spreading through society. Faced with this fear, people who invested most to secure themselves in the era of cognitive prowess - engineers and researchers - are those with the most to lose, and ironically are the people spreading this technology. This violent phase change makes consistent effort across a decade feel like a mistake. When a computational system can find novel mathematical theorems and new chemical compounds, suddenly the time we spent on learning a framework loses a lot of its economic and societal value.</p>

            <p>The natural human reaction of denial made our brightest engineers dismiss one of the highest technological levers of our time, but that's the biggest misconception. AI, or more generally Automated Cognitive Ability, will arguably receive more effort on improving it than we did with all the breakthrough technologies. The real power of humans was never cognition; it was vision.</p>

            <blockquote>
                <p>Humans are visionaries.<br />
                Not hunter-gatherers.<br />
                Not warriors.<br />
                Not coal-shoveling mechanics.<br />
                Not engineers.<br />
                Humans are visionaries.</p>
            </blockquote>

            <p>Our most powerful ability isn't that we are able to do what we do; it is that we want to do what we do. Abstractions open up a novel application layer for our ambitions, and AI is just that.</p>

            <hr />

            <h2>Conclusion</h2>

            <p>Don't spend most of your time in a sunk cost fallacy mindset to prove your worth<sup><a href="#ref6">[6]</a></sup>. Look inside, think about what really drives you, and know that the new frontier is there. You developed discipline and imagination to develop your cognitive skills, and now you will do the same for your vision.</p>

            <hr />

            <footer>
                <p id="ref1"><strong>[1]</strong> <a href="https://openai.com/index/introducing-codex/">Introducing Codex - OpenAI</a></p>
                <p id="ref2"><strong>[2]</strong> <a href="https://docs.anthropic.com/en/docs/claude-code/overview">Claude Code Overview - Anthropic</a></p>
                <p id="ref3"><strong>[3]</strong> <a href="https://www.gartner.com/en/articles/context-engineering">Context Engineering - Gartner</a></p>
                <p id="ref4"><strong>[4]</strong> <a href="https://www.nature.com/articles/s41586-023-06004-9">Mathematical discoveries from program search with large language models - Nature</a></p>
                <p id="ref5"><strong>[5]</strong> <a href="https://openai.com/blog/webgpt/">WebGPT: Browser-assisted question-answering - OpenAI</a></p>
                <p id="ref6"><strong>[6]</strong> <a href="https://www.sciencedirect.com/science/article/pii/0749597885900494">The psychology of sunk cost - ScienceDirect</a></p>
            </footer>
        </article>

        <footer class="book-footer">
            <p>&copy; 2024 Nessim Ben Abbes</p>
        </footer>
    </div>
    <script>
        fetch('../header.html')
            .then(response => response.text())
            .then(data => {
                document.getElementById('header').innerHTML = data;
            });
    </script>
    <script src="../zarzis.js"></script>
</body>
</html>
